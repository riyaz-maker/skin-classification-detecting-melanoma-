{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "mp.set_start_method('fork', force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       image_id  melanoma  seborrheic_keratosis age_approximate     sex  \\\n",
      "0  ISIC_0000000       0.0                   0.0              55  female   \n",
      "1  ISIC_0000001       0.0                   0.0              30  female   \n",
      "2  ISIC_0000002       1.0                   0.0              60  female   \n",
      "3  ISIC_0000003       0.0                   0.0              30    male   \n",
      "4  ISIC_0000004       1.0                   0.0              80    male   \n",
      "\n",
      "                                          image_path  \n",
      "0  /Users/riyazshaik/Documents/nanu_challenge/ISI...  \n",
      "1  /Users/riyazshaik/Documents/nanu_challenge/ISI...  \n",
      "2  /Users/riyazshaik/Documents/nanu_challenge/ISI...  \n",
      "3  /Users/riyazshaik/Documents/nanu_challenge/ISI...  \n",
      "4  /Users/riyazshaik/Documents/nanu_challenge/ISI...  \n",
      "[True, True, True, True, True]\n"
     ]
    }
   ],
   "source": [
    "# paths to CSV files for groundtruths and metadata\n",
    "train_gt = pd.read_csv(\"/Users/riyazshaik/Documents/nanu_challenge/ISIC-2017_Training_Part3_GroundTruth.csv\")\n",
    "val_gt = pd.read_csv(\"/Users/riyazshaik/Documents/nanu_challenge/ISIC-2017_Validation_Part3_GroundTruth.csv\")\n",
    "\n",
    "train_meta = pd.read_csv(\"/Users/riyazshaik/Documents/nanu_challenge/ISIC-2017_Training_Data/ISIC-2017_Training_Data_metadata.csv\")\n",
    "val_meta = pd.read_csv(\"/Users/riyazshaik/Documents/nanu_challenge/ISIC-2017_Validation_Data/ISIC-2017_Validation_Data_metadata.csv\")\n",
    "\n",
    "# mergeing the labels and metadata on image_id\n",
    "train_df = pd.merge(train_gt, train_meta, on=\"image_id\", how=\"left\")\n",
    "val_df = pd.merge(val_gt, val_meta, on=\"image_id\", how=\"left\")\n",
    "\n",
    "# attaching image paths\n",
    "base_train = \"/Users/riyazshaik/Documents/nanu_challenge/ISIC-2017_Training_Data\"\n",
    "base_val = \"/Users/riyazshaik/Documents/nanu_challenge/ISIC-2017_Validation_Data\"\n",
    "\n",
    "train_df[\"image_path\"] = train_df[\"image_id\"].apply(lambda x: os.path.join(base_train, f\"{x}.jpg\"))\n",
    "val_df  [\"image_path\"] = val_df  [\"image_id\"].apply(lambda x: os.path.join(base_val,   f\"{x}.jpg\"))\n",
    "\n",
    "# checking the above operations\n",
    "print(train_df.head())\n",
    "print([os.path.exists(p) for p in train_df[\"image_path\"].head(5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metadata preprocessing\n",
    "for df in (train_df, val_df):\n",
    "    df[\"age_approximate\"] = pd.to_numeric(df[\"age_approximate\"], errors=\"coerce\")\n",
    "    \n",
    "age_imp = SimpleImputer(strategy=\"median\")\n",
    "train_df[\"age_scaled\"] = age_imp.fit_transform(train_df[[\"age_approximate\"]])\n",
    "val_df[\"age_scaled\"] = age_imp.transform(val_df[[\"age_approximate\"]])\n",
    "\n",
    "age_scl = StandardScaler()\n",
    "train_df[\"age_scaled\"] = age_scl.fit_transform(train_df[[\"age_scaled\"]])\n",
    "val_df[\"age_scaled\"] = age_scl.transform(val_df[[\"age_scaled\"]])\n",
    "\n",
    "for col in train_df.columns:\n",
    "    if col.startswith(\"sex_\") and col not in val_df.columns:\n",
    "        val_df[col] = 0\n",
    "for col in val_df.columns:\n",
    "    if col.startswith(\"sex_\") and col not in train_df.columns:\n",
    "        train_df[col] = 0\n",
    "\n",
    "meta_cols = [\"age_scaled\"] + [c for c in train_df.columns if c.startswith(\"sex_\")]\n",
    "\n",
    "for df in (train_df, val_df):\n",
    "    df[meta_cols] = (\n",
    "        df[meta_cols]\n",
    "        .apply(pd.to_numeric, errors=\"coerce\")\n",
    "        .fillna(0)\n",
    "        .astype(np.float32)\n",
    "    )\n",
    "\n",
    "# useful transforms\n",
    "data_transforms = {\n",
    "    \"train\": transforms.Compose([\n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n",
    "    ]),\n",
    "    \"val\": transforms.Compose([\n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom dataset\n",
    "class ISICMetaDataset(Dataset):\n",
    "    def __init__(self, df, meta_cols, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.meta_cols = meta_cols\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        # load & transform images\n",
    "        img = Image.open(row[\"image_path\"]).convert(\"RGB\")\n",
    "        img = self.transform(img) if self.transform else img\n",
    "\n",
    "        # metadata extraction\n",
    "        import numpy as np\n",
    "        meta_vals = np.array(row[self.meta_cols].values, dtype=np.float32)\n",
    "        meta = torch.from_numpy(meta_vals)\n",
    "\n",
    "        label = torch.tensor(int(row[\"melanoma\"]), dtype=torch.long)\n",
    "        return img, meta, label\n",
    "\n",
    "# dataloaders for training and validation\n",
    "batch_size = 16\n",
    "train_ds = ISICMetaDataset(train_df, meta_cols, transform=data_transforms[\"train\"])\n",
    "val_ds = ISICMetaDataset(val_df, meta_cols, transform=data_transforms[\"val\"])\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imgs: torch.Size([16, 3, 224, 224]) metas: torch.Size([16, 4]) torch.float32 labels: torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "# checking the operations are working (learned to always check - hard way through experience)\n",
    "imgs, metas, labels = next(iter(train_loader))\n",
    "print(\"imgs:\", imgs.shape, \"metas:\", metas.shape, metas.dtype, \"labels:\", labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (bn2.bias, bn2.num_batches_tracked, bn2.running_mean, bn2.running_var, bn2.weight, classifier.bias, classifier.weight, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EnhancedHybridECAFiLM(\n",
      "  (backbone): EfficientNetFeatures(\n",
      "    (conv_stem): Conv2d(3, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNormAct2d(\n",
      "      40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "      (drop): Identity()\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (blocks): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): DepthwiseSeparableConv(\n",
      "          (conv_dw): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n",
      "          (bn1): BatchNormAct2d(\n",
      "            40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (aa): Identity()\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pw): Conv2d(40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn2): BatchNormAct2d(\n",
      "            24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (1): DepthwiseSeparableConv(\n",
      "          (conv_dw): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n",
      "          (bn1): BatchNormAct2d(\n",
      "            24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (aa): Identity()\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(24, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(6, 24, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pw): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn2): BatchNormAct2d(\n",
      "            24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): InvertedResidual(\n",
      "          (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNormAct2d(\n",
      "            144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
      "          (bn2): BatchNormAct2d(\n",
      "            144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (aa): Identity()\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNormAct2d(\n",
      "            32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (1): InvertedResidual(\n",
      "          (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNormAct2d(\n",
      "            192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "          (bn2): BatchNormAct2d(\n",
      "            192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (aa): Identity()\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNormAct2d(\n",
      "            32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (2): InvertedResidual(\n",
      "          (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNormAct2d(\n",
      "            192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "          (bn2): BatchNormAct2d(\n",
      "            192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (aa): Identity()\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNormAct2d(\n",
      "            32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "      )\n",
      "      (2): Sequential(\n",
      "        (0): InvertedResidual(\n",
      "          (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNormAct2d(\n",
      "            192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv_dw): Conv2d(192, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=192, bias=False)\n",
      "          (bn2): BatchNormAct2d(\n",
      "            192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (aa): Identity()\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNormAct2d(\n",
      "            48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (1): InvertedResidual(\n",
      "          (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNormAct2d(\n",
      "            288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv_dw): Conv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)\n",
      "          (bn2): BatchNormAct2d(\n",
      "            288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (aa): Identity()\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNormAct2d(\n",
      "            48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (2): InvertedResidual(\n",
      "          (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNormAct2d(\n",
      "            288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv_dw): Conv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)\n",
      "          (bn2): BatchNormAct2d(\n",
      "            288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (aa): Identity()\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNormAct2d(\n",
      "            48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "      )\n",
      "      (3): Sequential(\n",
      "        (0): InvertedResidual(\n",
      "          (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNormAct2d(\n",
      "            288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)\n",
      "          (bn2): BatchNormAct2d(\n",
      "            288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (aa): Identity()\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNormAct2d(\n",
      "            96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (1): InvertedResidual(\n",
      "          (conv_pw): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNormAct2d(\n",
      "            576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv_dw): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "          (bn2): BatchNormAct2d(\n",
      "            576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (aa): Identity()\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNormAct2d(\n",
      "            96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (2): InvertedResidual(\n",
      "          (conv_pw): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNormAct2d(\n",
      "            576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv_dw): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "          (bn2): BatchNormAct2d(\n",
      "            576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (aa): Identity()\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNormAct2d(\n",
      "            96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (3): InvertedResidual(\n",
      "          (conv_pw): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNormAct2d(\n",
      "            576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv_dw): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "          (bn2): BatchNormAct2d(\n",
      "            576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (aa): Identity()\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNormAct2d(\n",
      "            96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (4): InvertedResidual(\n",
      "          (conv_pw): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNormAct2d(\n",
      "            576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv_dw): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "          (bn2): BatchNormAct2d(\n",
      "            576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (aa): Identity()\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNormAct2d(\n",
      "            96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "      )\n",
      "      (4): Sequential(\n",
      "        (0): InvertedResidual(\n",
      "          (conv_pw): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNormAct2d(\n",
      "            576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv_dw): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
      "          (bn2): BatchNormAct2d(\n",
      "            576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (aa): Identity()\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNormAct2d(\n",
      "            136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (1): InvertedResidual(\n",
      "          (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNormAct2d(\n",
      "            816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv_dw): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)\n",
      "          (bn2): BatchNormAct2d(\n",
      "            816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (aa): Identity()\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNormAct2d(\n",
      "            136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (2): InvertedResidual(\n",
      "          (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNormAct2d(\n",
      "            816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv_dw): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)\n",
      "          (bn2): BatchNormAct2d(\n",
      "            816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (aa): Identity()\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNormAct2d(\n",
      "            136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (3): InvertedResidual(\n",
      "          (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNormAct2d(\n",
      "            816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv_dw): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)\n",
      "          (bn2): BatchNormAct2d(\n",
      "            816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (aa): Identity()\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNormAct2d(\n",
      "            136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (4): InvertedResidual(\n",
      "          (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNormAct2d(\n",
      "            816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv_dw): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)\n",
      "          (bn2): BatchNormAct2d(\n",
      "            816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (aa): Identity()\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNormAct2d(\n",
      "            136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "      )\n",
      "      (5): Sequential(\n",
      "        (0): InvertedResidual(\n",
      "          (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNormAct2d(\n",
      "            816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv_dw): Conv2d(816, 816, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=816, bias=False)\n",
      "          (bn2): BatchNormAct2d(\n",
      "            816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (aa): Identity()\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNormAct2d(\n",
      "            232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (1): InvertedResidual(\n",
      "          (conv_pw): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNormAct2d(\n",
      "            1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv_dw): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n",
      "          (bn2): BatchNormAct2d(\n",
      "            1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (aa): Identity()\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNormAct2d(\n",
      "            232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (2): InvertedResidual(\n",
      "          (conv_pw): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNormAct2d(\n",
      "            1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv_dw): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n",
      "          (bn2): BatchNormAct2d(\n",
      "            1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (aa): Identity()\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNormAct2d(\n",
      "            232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (3): InvertedResidual(\n",
      "          (conv_pw): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNormAct2d(\n",
      "            1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv_dw): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n",
      "          (bn2): BatchNormAct2d(\n",
      "            1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (aa): Identity()\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNormAct2d(\n",
      "            232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (4): InvertedResidual(\n",
      "          (conv_pw): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNormAct2d(\n",
      "            1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv_dw): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n",
      "          (bn2): BatchNormAct2d(\n",
      "            1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (aa): Identity()\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNormAct2d(\n",
      "            232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (5): InvertedResidual(\n",
      "          (conv_pw): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNormAct2d(\n",
      "            1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv_dw): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n",
      "          (bn2): BatchNormAct2d(\n",
      "            1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (aa): Identity()\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNormAct2d(\n",
      "            232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "      )\n",
      "      (6): Sequential(\n",
      "        (0): InvertedResidual(\n",
      "          (conv_pw): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNormAct2d(\n",
      "            1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv_dw): Conv2d(1392, 1392, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1392, bias=False)\n",
      "          (bn2): BatchNormAct2d(\n",
      "            1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (aa): Identity()\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNormAct2d(\n",
      "            384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (1): InvertedResidual(\n",
      "          (conv_pw): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNormAct2d(\n",
      "            2304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv_dw): Conv2d(2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)\n",
      "          (bn2): BatchNormAct2d(\n",
      "            2304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (aa): Identity()\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNormAct2d(\n",
      "            384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (eca): ECA(\n",
      "    (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "    (conv): Conv1d(1, 1, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
      "    (sigmoid): Sigmoid()\n",
      "  )\n",
      "  (film): FiLM(\n",
      "    (gamma): Linear(in_features=4, out_features=384, bias=True)\n",
      "    (beta): Linear(in_features=4, out_features=384, bias=True)\n",
      "  )\n",
      "  (pool): AdaptiveAvgPool2d(output_size=1)\n",
      "  (meta_mlp): Sequential(\n",
      "    (0): Linear(in_features=4, out_features=384, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.2, inplace=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=384, out_features=256, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=256, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# efficient channel attention implementation\n",
    "class ECA(nn.Module):\n",
    "    def __init__(self, channels, k_size=3):\n",
    "        super().__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.conv = nn.Conv1d(1, 1, kernel_size=k_size, padding=(k_size-1)//2, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.avg_pool(x)\n",
    "        y = y.squeeze(-1).transpose(1, 2)\n",
    "        y = self.conv(y)\n",
    "        y = self.sigmoid(y).transpose(1, 2)\n",
    "        y = y.unsqueeze(-1)\n",
    "        return x * y.expand_as(x)\n",
    "\n",
    "# feature wise linear modulation implementation\n",
    "class FiLM(nn.Module):\n",
    "    def __init__(self, feat_ch, meta_dim):\n",
    "        super().__init__()\n",
    "        self.gamma = nn.Linear(meta_dim, feat_ch)\n",
    "        self.beta = nn.Linear(meta_dim, feat_ch)\n",
    "\n",
    "    def forward(self, x, meta):\n",
    "        g = self.gamma(meta).unsqueeze(-1).unsqueeze(-1)\n",
    "        b = self.beta(meta).unsqueeze(-1).unsqueeze(-1)\n",
    "        return x * (1 + g) + b\n",
    "\n",
    "# hybrid model: efficientnet-b3 + ECA + FiLM + Meta-MLP + classifier\n",
    "class EnhancedHybridECAFiLM(nn.Module):\n",
    "    def __init__(self, meta_feat_dim, num_classes=2, backbone_name=\"efficientnet_b3\"):\n",
    "        super().__init__()\n",
    "        # efficientnet backbone\n",
    "        self.backbone = timm.create_model(backbone_name, pretrained=True, features_only=True)\n",
    "        channels = self.backbone.feature_info.channels()\n",
    "        fin_ch = channels[-1]\n",
    "\n",
    "        # ECA on final feature map\n",
    "        self.eca = ECA(fin_ch, k_size=3)\n",
    "        self.film = FiLM(fin_ch, meta_feat_dim)\n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "        # metadata mlp\n",
    "        self.meta_mlp = nn.Sequential(\n",
    "            nn.Linear(meta_feat_dim, fin_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.2),\n",
    "        )\n",
    "\n",
    "        # classification head\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(fin_ch, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, img, meta):\n",
    "        feats = self.backbone(img)\n",
    "        fin_feat = feats[-1]\n",
    "        x = self.eca(fin_feat)\n",
    "        x = self.film(x, meta)\n",
    "        x = self.pool(x).flatten(1)\n",
    "        m = self.meta_mlp(meta)\n",
    "\n",
    "        out = self.classifier(x + m)\n",
    "        return out\n",
    "\n",
    "meta_feat_dim = len(meta_cols)\n",
    "model = EnhancedHybridECAFiLM(meta_feat_dim=meta_feat_dim, num_classes=2).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa1725f4b2ac4bb0a22d2115123dbd98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/20 [train]:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "689e3c78e97a46a089d49196877be089",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       " [val] :   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 01] train loss: 0.0206 | val AUC: 0.8397 | sens: 0.9000 | spec: 0.5333 | thr: 0.195\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f9838d79c984ce8a7b026438c89c4be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/20 [train]:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c037627bc6643658e9045020cc3cf36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       " [val] :   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 02] train loss: 0.0172 | val AUC: 0.8503 | sens: 0.9333 | spec: 0.5083 | thr: 0.199\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef4f8f46b3464ebeaf6969644b456b17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/20 [train]:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5670a6f6a1ae4b2e93430af892cbef10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       " [val] :   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 03] train loss: 0.0156 | val AUC: 0.8619 | sens: 0.9333 | spec: 0.7167 | thr: 0.255\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fd69d6629d04d00add6d0b209308e15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/20 [train]:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c81aa3caf334aebb74b606e58cffd66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       " [val] :   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 04] train loss: 0.0149 | val AUC: 0.8969 | sens: 0.9333 | spec: 0.5250 | thr: 0.166\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10b8c50018ed43dcb4a18d2596522080",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/20 [train]:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e7de9bec48e4720b87a401ec5b6d181",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       " [val] :   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 05] train loss: 0.0146 | val AUC: 0.8542 | sens: 0.9000 | spec: 0.5917 | thr: 0.183\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f88b9b9cf6a4868b4f20e5f0f17ff0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6/20 [train]:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "525ee1338b6e43028556535969b91676",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       " [val] :   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 06] train loss: 0.0127 | val AUC: 0.9025 | sens: 1.0000 | spec: 0.5083 | thr: 0.052\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6aa042fa78164887a28b57f59dbfdd2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7/20 [train]:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2249abf7c4b4099b17ed2c39f426a13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       " [val] :   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 07] train loss: 0.0093 | val AUC: 0.9250 | sens: 0.9667 | spec: 0.5333 | thr: 0.047\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9b4f5c47227408899bdaafd11036652",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8/20 [train]:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81f09c68c4464cd79e4e1355b7c13ad0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       " [val] :   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 08] train loss: 0.0084 | val AUC: 0.8289 | sens: 0.9333 | spec: 0.5417 | thr: 0.016\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ac0b5ad94ee4c789cbd0d7a6ca3bddf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9/20 [train]:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37b79009045147d78a7618be1a7363a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       " [val] :   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 09] train loss: 0.0064 | val AUC: 0.9031 | sens: 1.0000 | spec: 0.5500 | thr: 0.037\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c65e616bb694dfb9b4bde4f58f246d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10/20 [train]:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42d88b16cc2e4fd588b75a0694714114",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       " [val] :   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 10] train loss: 0.0057 | val AUC: 0.8833 | sens: 0.9667 | spec: 0.6167 | thr: 0.060\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a6d2f7cfe804171bd5e158a3b795373",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 11/20 [train]:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a8103d79a314778a5daaed82536b48d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       " [val] :   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 11] train loss: 0.0038 | val AUC: 0.8850 | sens: 1.0000 | spec: 0.5333 | thr: 0.019\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "631daa34a5f94a9b8ab7e3fbe6b929ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 12/20 [train]:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f095e29f6b944bed8c69704e7988e16e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       " [val] :   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 12] train loss: 0.0029 | val AUC: 0.8592 | sens: 0.9667 | spec: 0.5000 | thr: 0.009\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ec42b2f837c480c8ee78bdbca5604b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 13/20 [train]:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb11db6bf9d74a15ace2259438b9a12a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       " [val] :   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 13] train loss: 0.0025 | val AUC: 0.9064 | sens: 1.0000 | spec: 0.6083 | thr: 0.022\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a6a52bbde914180910cf7ff6ea66cc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 14/20 [train]:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0a663729d724f569740cc0b6add88e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       " [val] :   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 14] train loss: 0.0012 | val AUC: 0.8900 | sens: 0.9667 | spec: 0.5333 | thr: 0.012\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "652f2e7a51124b56a41091d7c1f7032c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 15/20 [train]:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8909357eea8b4f5eb6219cc748e73451",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       " [val] :   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 15] train loss: 0.0026 | val AUC: 0.8792 | sens: 1.0000 | spec: 0.5833 | thr: 0.018\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17ff3e86505b402489bb1c133a9d879c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 16/20 [train]:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "038412c8fad14c708fe84b51570988d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       " [val] :   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 16] train loss: 0.0012 | val AUC: 0.8753 | sens: 1.0000 | spec: 0.5417 | thr: 0.011\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71e83f542d154fa68a87e0bdcf1db1e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 17/20 [train]:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79b821f1ff6946668155c30493dc828c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       " [val] :   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 17] train loss: 0.0010 | val AUC: 0.8753 | sens: 0.9667 | spec: 0.5833 | thr: 0.020\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b6e64a8e98545e995c872dd981ecb2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 18/20 [train]:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97a849682be1418b99877371085c5175",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       " [val] :   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 18] train loss: 0.0010 | val AUC: 0.8747 | sens: 1.0000 | spec: 0.5000 | thr: 0.014\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f93e5db7e8242cda36edd22aa15b666",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 19/20 [train]:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[65], line 86\u001b[0m\n\u001b[1;32m     84\u001b[0m best_auc \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, epochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m---> 86\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m train_epoch(model, train_loader, criterion, optimizer, scheduler, device, epoch, epochs)\n\u001b[1;32m     87\u001b[0m     val_auc, val_sens, val_spec, thr_used \u001b[38;5;241m=\u001b[39m validate(model, val_loader, device, min_spec\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.50\u001b[39m)\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m val_auc \u001b[38;5;241m>\u001b[39m best_auc:\n",
      "Cell \u001b[0;32mIn[65], line 44\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(model, loader, criterion, optimizer, scheduler, device, epoch, total_epochs)\u001b[0m\n\u001b[1;32m     42\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     43\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 44\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     45\u001b[0m scheduler\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     47\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m imgs\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:124\u001b[0m, in \u001b[0;36mLRScheduler.__init__.<locals>.patch_track_step_called.<locals>.wrap_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    122\u001b[0m opt \u001b[38;5;241m=\u001b[39m opt_ref()\n\u001b[1;32m    123\u001b[0m opt\u001b[38;5;241m.\u001b[39m_opt_called \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__get__\u001b[39m(opt, opt\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/optim/optimizer.py:485\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    480\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    481\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    482\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    483\u001b[0m             )\n\u001b[0;32m--> 485\u001b[0m out \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    486\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    488\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/optim/optimizer.py:79\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     77\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 79\u001b[0m     ret \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     81\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/optim/adam.py:246\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    234\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    236\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    237\u001b[0m         group,\n\u001b[1;32m    238\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    243\u001b[0m         state_steps,\n\u001b[1;32m    244\u001b[0m     )\n\u001b[0;32m--> 246\u001b[0m     adam(\n\u001b[1;32m    247\u001b[0m         params_with_grad,\n\u001b[1;32m    248\u001b[0m         grads,\n\u001b[1;32m    249\u001b[0m         exp_avgs,\n\u001b[1;32m    250\u001b[0m         exp_avg_sqs,\n\u001b[1;32m    251\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    252\u001b[0m         state_steps,\n\u001b[1;32m    253\u001b[0m         amsgrad\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mamsgrad\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    254\u001b[0m         has_complex\u001b[38;5;241m=\u001b[39mhas_complex,\n\u001b[1;32m    255\u001b[0m         beta1\u001b[38;5;241m=\u001b[39mbeta1,\n\u001b[1;32m    256\u001b[0m         beta2\u001b[38;5;241m=\u001b[39mbeta2,\n\u001b[1;32m    257\u001b[0m         lr\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    258\u001b[0m         weight_decay\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweight_decay\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    259\u001b[0m         eps\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meps\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    260\u001b[0m         maximize\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    261\u001b[0m         foreach\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforeach\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    262\u001b[0m         capturable\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcapturable\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    263\u001b[0m         differentiable\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    264\u001b[0m         fused\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfused\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    265\u001b[0m         grad_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrad_scale\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m    266\u001b[0m         found_inf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m    267\u001b[0m         decoupled_weight_decay\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecoupled_weight_decay\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    268\u001b[0m     )\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/optim/optimizer.py:147\u001b[0m, in \u001b[0;36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/optim/adam.py:933\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, decoupled_weight_decay, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    930\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    931\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 933\u001b[0m func(\n\u001b[1;32m    934\u001b[0m     params,\n\u001b[1;32m    935\u001b[0m     grads,\n\u001b[1;32m    936\u001b[0m     exp_avgs,\n\u001b[1;32m    937\u001b[0m     exp_avg_sqs,\n\u001b[1;32m    938\u001b[0m     max_exp_avg_sqs,\n\u001b[1;32m    939\u001b[0m     state_steps,\n\u001b[1;32m    940\u001b[0m     amsgrad\u001b[38;5;241m=\u001b[39mamsgrad,\n\u001b[1;32m    941\u001b[0m     has_complex\u001b[38;5;241m=\u001b[39mhas_complex,\n\u001b[1;32m    942\u001b[0m     beta1\u001b[38;5;241m=\u001b[39mbeta1,\n\u001b[1;32m    943\u001b[0m     beta2\u001b[38;5;241m=\u001b[39mbeta2,\n\u001b[1;32m    944\u001b[0m     lr\u001b[38;5;241m=\u001b[39mlr,\n\u001b[1;32m    945\u001b[0m     weight_decay\u001b[38;5;241m=\u001b[39mweight_decay,\n\u001b[1;32m    946\u001b[0m     eps\u001b[38;5;241m=\u001b[39meps,\n\u001b[1;32m    947\u001b[0m     maximize\u001b[38;5;241m=\u001b[39mmaximize,\n\u001b[1;32m    948\u001b[0m     capturable\u001b[38;5;241m=\u001b[39mcapturable,\n\u001b[1;32m    949\u001b[0m     differentiable\u001b[38;5;241m=\u001b[39mdifferentiable,\n\u001b[1;32m    950\u001b[0m     grad_scale\u001b[38;5;241m=\u001b[39mgrad_scale,\n\u001b[1;32m    951\u001b[0m     found_inf\u001b[38;5;241m=\u001b[39mfound_inf,\n\u001b[1;32m    952\u001b[0m     decoupled_weight_decay\u001b[38;5;241m=\u001b[39mdecoupled_weight_decay,\n\u001b[1;32m    953\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/optim/adam.py:405\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, decoupled_weight_decay)\u001b[0m\n\u001b[1;32m    402\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weight_decay \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    403\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m decoupled_weight_decay:\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;66;03m# Perform stepweight decay\u001b[39;00m\n\u001b[0;32m--> 405\u001b[0m         param\u001b[38;5;241m.\u001b[39mmul_(\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m lr \u001b[38;5;241m*\u001b[39m weight_decay)\n\u001b[1;32m    406\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    407\u001b[0m         \u001b[38;5;66;03m# Nested if is necessary to bypass jitscript rules\u001b[39;00m\n\u001b[1;32m    408\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m differentiable \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(weight_decay, Tensor):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# training setup using focal loss and one cycle lr scheduler\n",
    "# focal loss implementation\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2.0, alpha=0.25, reduction='mean'):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        ce = nn.functional.cross_entropy(logits, targets, reduction='none')\n",
    "        p = torch.exp(-ce)\n",
    "        loss = self.alpha * (1 - p)**self.gamma * ce\n",
    "        return loss.mean() if self.reduction=='mean' else loss.sum()\n",
    "\n",
    "criterion = FocalLoss(gamma=2.0, alpha=0.25)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=3e-4, weight_decay=1e-5)\n",
    "\n",
    "# one cycle lr scheduler\n",
    "epochs = 20\n",
    "steps_per_ep = len(train_loader)\n",
    "scheduler = OneCycleLR(optimizer, max_lr=3e-4, total_steps=epochs * steps_per_ep, pct_start=0.3, anneal_strategy='cos',\n",
    "                          div_factor=10,\n",
    "                          final_div_factor=100)\n",
    "\n",
    "def train_epoch(model, loader, criterion, optimizer, scheduler, device, epoch, total_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    loop = tqdm(loader, desc=f\"Epoch {epoch}/{total_epochs} [train]\", leave=False)\n",
    "    for imgs, metas, labels in loop:\n",
    "        imgs, metas, labels = imgs.to(device), metas.to(device), labels.to(device)\n",
    "        logits = model(imgs, metas)\n",
    "        loss = criterion(logits, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        running_loss += loss.item() * imgs.size(0)\n",
    "        loop.set_postfix({\n",
    "            \"loss\": f\"{loss.item():.4f}\",\n",
    "            \"lr\": f\"{optimizer.param_groups[0]['lr']:.2e}\"\n",
    "        })\n",
    "    return running_loss / len(loader.dataset)\n",
    "\n",
    "def validate(model, loader, device, min_spec=0.50):\n",
    "    model.eval()\n",
    "    y_true, y_prob = [], []\n",
    "    loop = tqdm(loader, desc=\" [val] \", leave=False)\n",
    "    with torch.no_grad():\n",
    "        for imgs, metas, labels in loop:\n",
    "            imgs, metas = imgs.to(device), metas.to(device)\n",
    "            logits = model(imgs, metas)\n",
    "            probs = F.softmax(logits, dim=1)[:, 1]\n",
    "            y_true.extend(labels.tolist())\n",
    "            y_prob.extend(probs.cpu().tolist())\n",
    "\n",
    "            if len(labels.unique()) > 1:\n",
    "                loop.set_postfix(\n",
    "                    {\"batch AUC\": f\"{roc_auc_score(labels.cpu(), probs.cpu()):.3f}\"}\n",
    "                )\n",
    "    # computing metrics\n",
    "    y_true = np.array(y_true)\n",
    "    y_prob = np.array(y_prob)\n",
    "    auc = roc_auc_score(y_true, y_prob)\n",
    "    fpr, tpr, thr = roc_curve(y_true, y_prob)\n",
    "    spec = 1 - fpr\n",
    "    mask = spec >= min_spec\n",
    "    best = np.argmax(tpr * mask) if mask.any() else np.argmax(tpr)\n",
    "    thr_used = thr[best]\n",
    "    sensitivity = tpr[best]\n",
    "    specificity = spec[best]\n",
    "\n",
    "    return auc, sensitivity, specificity, thr_used\n",
    "\n",
    "best_auc = 0.0\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train_loss = train_epoch(model, train_loader, criterion, optimizer, scheduler, device, epoch, epochs)\n",
    "    val_auc, val_sens, val_spec, thr_used = validate(model, val_loader, device, min_spec=0.50)\n",
    "\n",
    "    if val_auc > best_auc:\n",
    "        best_auc = val_auc\n",
    "        torch.save(model.state_dict(), \"best_model.pth\")\n",
    "\n",
    "    print(\n",
    "        f\"[epoch {epoch:02d}] \"\n",
    "        f\"train loss: {train_loss:.4f} | \"\n",
    "        f\"val AUC: {val_auc:.4f} | \"\n",
    "        f\"sens: {val_sens:.4f} | \"\n",
    "        f\"spec: {val_spec:.4f} | \"\n",
    "        f\"thr: {thr_used:.3f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performing operations similar to train and validate on test dataset \n",
    "test_gt = pd.read_csv(\"/Users/riyazshaik/Documents/nanu_challenge/ISIC-2017_Test_v2_Part3_GroundTruth.csv\")\n",
    "test_meta = pd.read_csv(\"/Users/riyazshaik/Documents/nanu_challenge/ISIC-2017_Test_v2_Data/ISIC-2017_Test_v2_Data_metadata.csv\")\n",
    "\n",
    "# mergeing the labels and metadata on image_id\n",
    "test_df = pd.merge(test_gt, test_meta, on=\"image_id\", how=\"left\")\n",
    "base_test = \"/Users/riyazshaik/Documents/nanu_challenge/ISIC-2017_Test_v2_Data\"\n",
    "test_df[\"image_path\"] = test_df[\"image_id\"].apply(lambda x: os.path.join(base_test, f\"{x}.jpg\"))\n",
    "\n",
    "# metadata preprocessing\n",
    "test_df[\"age_approximate\"] = pd.to_numeric(test_df[\"age_approximate\"], errors=\"coerce\")\n",
    "test_df[\"age_scaled\"] = age_imp.transform(test_df[[\"age_approximate\"]])\n",
    "test_df[\"age_scaled\"] = age_scl.transform(test_df[[\"age_scaled\"]])\n",
    "test_df = pd.get_dummies(test_df, columns=[\"sex\"], prefix=\"sex\", dummy_na=False)\n",
    "for col in [c for c in meta_cols if c.startswith(\"sex_\")]:\n",
    "    if col not in test_df.columns:\n",
    "        test_df[col] = 0\n",
    "\n",
    "test_df[meta_cols] = test_df[meta_cols].astype(np.float32)\n",
    "\n",
    "# dataloader for test dataset\n",
    "test_ds = ISICMetaDataset(test_df, meta_cols, transform=data_transforms[\"val\"])\n",
    "test_loader = DataLoader(test_ds, batch_size=16, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Accuracy @0.5 : 0.848\n",
      "test Sensitivity @0.5 : 0.632\n",
      "test Specificity @0.5 : 0.901\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.90      0.91       483\n",
      "         1.0       0.61      0.63      0.62       117\n",
      "\n",
      "    accuracy                           0.85       600\n",
      "   macro avg       0.76      0.77      0.76       600\n",
      "weighted avg       0.85      0.85      0.85       600\n",
      "\n",
      "saved test_results_with_truth.csv with 600 rows\n"
     ]
    }
   ],
   "source": [
    "# loading the best model for testing\n",
    "model.load_state_dict(torch.load(\"best_model.pth\", map_location=device))\n",
    "model.to(device).eval()\n",
    "\n",
    "image_ids, probs = [], []\n",
    "with torch.no_grad():\n",
    "    for imgs, metas, _ in test_loader:\n",
    "        imgs, metas = imgs.to(device), metas.to(device)\n",
    "        logits = model(imgs, metas)\n",
    "        batch_probs = torch.softmax(logits, dim=1)[:, 1].cpu().numpy()\n",
    "        probs.extend(batch_probs)\n",
    "        start = len(image_ids)\n",
    "        image_ids.extend(test_df[\"image_id\"].iloc[start:start + len(batch_probs)].tolist())\n",
    "\n",
    "# building results dataframe and merging with ground truth for evaluation\n",
    "results_df = pd.DataFrame({\n",
    "    \"image_id\": image_ids,\n",
    "    \"prob_melanoma\": probs\n",
    "}).merge(test_df[[\"image_id\", \"melanoma\"]], on=\"image_id\")\n",
    "\n",
    "# computing predicted label at 0.5\n",
    "results_df[\"pred_label\"] = (results_df[\"prob_melanoma\"] > 0.5).astype(int)\n",
    "results_df[\"correct\"] = results_df[\"pred_label\"] == results_df[\"melanoma\"]\n",
    "\n",
    "acc = accuracy_score(results_df[\"melanoma\"], results_df[\"pred_label\"])\n",
    "tn, fp, fn, tp = confusion_matrix(results_df[\"melanoma\"], results_df[\"pred_label\"]).ravel()\n",
    "sens = tp / (tp + fn)\n",
    "spec = tn / (tn + fp)\n",
    "\n",
    "print(f\"test Accuracy @0.5 : {acc:.3f}\")\n",
    "print(f\"test Sensitivity @0.5 : {sens:.3f}\")\n",
    "print(f\"test Specificity @0.5 : {spec:.3f}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(results_df[\"melanoma\"], results_df[\"pred_label\"]))\n",
    "results_df.to_csv(\"test_results_with_truth.csv\", index=False)\n",
    "print(\"saved test_results_with_truth.csv with\", len(results_df), \"rows\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
